{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlAk8cZ+YKJFiC/nrTvtSX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# install librarys"],"metadata":{"id":"CLg9xTDBDYYY"}},{"cell_type":"code","source":["!pip install -U langchain_openai\n","!pip install -U huggingface_hub\n","!pip install -U langchain_community\n","!pip install -U pydantic"],"metadata":{"id":"V-pYz7jY0Ntu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760595304486,"user_tz":-210,"elapsed":44313,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"}},"outputId":"711fcfc3-ef51-45ef-e154-14a560a76dcf"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_openai\n","  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.3.78)\n","Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.33)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (6.0.3)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.15.0)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (25.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.11.10)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain_openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n","Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain_openai\n","Successfully installed langchain_openai-0.3.35\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.35.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.10)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.10.5)\n","Collecting langchain_community\n","  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n","Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n","Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n","Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n","  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n","Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.33)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.2)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.10)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n","Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.32.4\n","    Uninstalling requests-2.32.4:\n","      Successfully uninstalled requests-2.32.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.31 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n","Collecting pydantic\n","  Downloading pydantic-2.12.2-py3-none-any.whl.metadata (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n","Collecting pydantic-core==2.41.4 (from pydantic)\n","  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n","Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n","Downloading pydantic-2.12.2-py3-none-any.whl (460 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n","  Attempting uninstall: pydantic-core\n","    Found existing installation: pydantic_core 2.33.2\n","    Uninstalling pydantic_core-2.33.2:\n","      Successfully uninstalled pydantic_core-2.33.2\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.11.10\n","    Uninstalling pydantic-2.11.10:\n","      Successfully uninstalled pydantic-2.11.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gradio 5.49.0 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pydantic-2.12.2 pydantic-core-2.41.4\n","Requirement already satisfied: fastapi[standard] in /usr/local/lib/python3.12/dist-packages (0.118.2)\n","Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (0.48.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (2.12.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (4.15.0)\n","Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard])\n","  Downloading fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (0.28.1)\n","Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (3.1.6)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]) (0.0.20)\n","Collecting email-validator>=2.0.0 (from fastapi[standard])\n","  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n","Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (0.37.0)\n","Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard])\n","  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]) (3.10)\n","Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (0.19.2)\n","Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard])\n","  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n","Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard])\n","  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.5->fastapi[standard]) (3.0.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (0.4.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (8.3.0)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n","  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (1.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (6.0.3)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n","  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n","  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (15.0.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0,>=0.23.0->fastapi[standard]) (1.3.1)\n","Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard])\n","  Downloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (2.40.0)\n","Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (13.9.4)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (1.5.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (2.19.2)\n","Requirement already satisfied: urllib3>=1.26.11 in /usr/local/lib/python3.12/dist-packages (from sentry-sdk>=2.20.0->fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (2.5.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]) (0.1.2)\n","Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n","Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n","Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n","Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n","Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.9/951.9 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: uvloop, rignore, httptools, dnspython, watchfiles, email-validator, rich-toolkit, fastapi-cloud-cli, fastapi-cli\n","Successfully installed dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.13 fastapi-cloud-cli-0.3.1 httptools-0.7.1 rich-toolkit-0.15.1 rignore-0.7.1 uvloop-0.21.0 watchfiles-1.1.1\n"]}]},{"cell_type":"markdown","source":["## connect to OpenAI gpt API\n","To connect to the OpenAI GPT API, we utilized [AvalAi](https://avalai.ir/). After signing in, we generated an API key specifically for our project."],"metadata":{"id":"HdJXWKC6Fc2M"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI,OpenAI\n","from langchain_community.callbacks import get_openai_callback\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Hello world!\"},\n","]\n","model_name = \"gpt-4o-mini\" # in this case we want to use gpt-4o-mini\n","\n","\n","llm = ChatOpenAI(\n","    model=model_name,\n","    base_url=\"https://api.avalai.ir/v1\",\n","    temperature=None,\n","    max_tokens=3800, #token limiter\n","    timeout=None,\n","    max_retries=0,\n","\n","\n","\n","    api_key=\"aa-qQ83RCj6StMiojqP9GQXDzWUNENhEbKfBf0n2dKusfAKp7I7\"\n",")\n","# this is testing the API connection and tracking token usage\n","with get_openai_callback() as cb:\n","  response = llm.invoke(messages)\n","  print(cb)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75erZyaNEnnv","executionInfo":{"status":"ok","timestamp":1760510330593,"user_tz":-210,"elapsed":733,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"}},"outputId":"aa78f0a9-e569-43cf-de03-3592a742faee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens Used: 30\n","\tPrompt Tokens: 20\n","\t\tPrompt Tokens Cached: 0\n","\tCompletion Tokens: 10\n","\t\tReasoning Tokens: 0\n","Successful Requests: 1\n","Total Cost (USD): $8.999999999999999e-06\n"]}]},{"cell_type":"markdown","source":["## Creating a pydantic class for better output format"],"metadata":{"id":"IuBeUjiuIHxe"}},{"cell_type":"code","source":["from pydantic import BaseModel, Field, field_validator, model_validator\n","from typing import List, Dict\n","\n","\n","class ProductReviewGap(BaseModel):\n","    \"\"\"Represents gaps and review mentions for a single product.\"\"\"\n","    product_name: str = Field(description=\"Name of the product\")\n","    review_mentions: List[str] = Field(..., description=\"Features or topics mentioned by customers in reviews\")\n","    missing_in_description: List[str] = Field(..., description=\"Features mentioned in reviews but missing from product description (content gaps)\")\n","    # product name must not be empty\n","    @field_validator(\"product_name\")\n","    def validate_product_name(cls, v):\n","        \"\"\"Ensure product name is not empty or only whitespace.\"\"\"\n","        if not v.strip():\n","            raise ValueError(\"product_name cannot be empty or whitespace\")\n","        return v\n","\n","\n","class ContentGapAnalysisResult(BaseModel):\n","    \"\"\"Main model for the content gap analysis result.\"\"\"\n","    common_features: List[str] = Field(..., description=\"Features common to all products\")\n","    unique_features: Dict[str, List[str]] = Field(..., description=\"Unique features for each product; dictionary key = product name\")\n","    customer_gaps: List[ProductReviewGap] = Field(..., description=\"List of gaps and review mentions for each product\")\n","    marketing_insight: str = Field(description=\"A simple, business-oriented summary for the marketing team\")\n","    #key feild must not be empty\n","    @field_validator(\"marketing_insight\")\n","    def validate_not_empty(cls, v, info):\n","        \"\"\"Ensure marketing insight is not empty.\"\"\"\n","        if not v or not v.strip():\n","            raise ValueError(f\"{info.field_name} cannot be empty\")\n","        return v\n","    #Checking the compatibility of product names between different parts\n","    @model_validator(mode=\"after\")\n","    def validate_product_consistency(self):\n","        \"\"\"Ensure all products in customer_gaps exist in unique_features.\"\"\"\n","        if self.unique_features and self.customer_gaps:\n","            product_names_from_unique = set(self.unique_features.keys())\n","            product_names_from_gaps = {gap.product_name for gap in self.customer_gaps}\n","            missing = product_names_from_gaps - product_names_from_unique\n","            if missing:\n","                raise ValueError(\n","                    f\"Products in customer_gaps not found in unique_features: {', '.join(missing)}\"\n","                )\n","        return self\n"],"metadata":{"id":"ih0fDFjqISRd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Translating the key words for Farsi output"],"metadata":{"id":"w3Uz8JiItN6g"}},{"cell_type":"code","source":["# KEY_MAP = {\n","#     \"نام_محصول\": \"product_name\",\n","#     \"اشارات_در_نقد\": \"review_mentions\",\n","#     \"مفقود_در_توضیحات\": \"missing_in_description\",\n","#     \"ویژگی‌های_مشترک\": \"common_features\",\n","#     \"ویژگی‌های_منحصر_به_فرد\": \"unique_features\",\n","#     \"شکاف‌های_مشتری\": \"customer_gaps\",\n","#     \"بینش_بازاریابی\": \"marketing_insight\",\n","#     \"between_marketing_insights\": \"marketing_insight\"\n","# }\n","\n","# def translate_keys(data):\n","#     if isinstance(data, dict):\n","#         return {KEY_MAP.get(k, k): translate_keys(v) for k, v in data.items()}\n","#     elif isinstance(data, list):\n","#         return [translate_keys(item) for item in data]\n","#     return data"],"metadata":{"id":"LDLs4y8WtJDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def force_json_closure(text: str) -> str:\n","    match = re.search(r\"\\{.*\\}\", text, re.S)\n","    if match:\n","        return match.group()\n","    return \"{}\"\n","# better output format with EN-FA sentences\n","def normalize_mixed_text(text: str) -> str:\n","    text = re.sub(r'[\\u200c\\s]+', ' ', text)\n","    text = re.sub(r'\\s+([,.!?;:])', r'\\1', text)\n","    text = re.sub(r'([،؛؟])\\s*', r'\\1 ', text)\n","    text = re.sub(r'([آ-ی])([A-Za-z0-9])', r'\\1 \\2', text)\n","    text = re.sub(r'([A-Za-z0-9])([آ-ی])', r'\\1 \\2', text)\n","    text = re.sub(r'\\(\\s+', '(', text)\n","    text = re.sub(r'\\s+\\)', ')', text)\n","    return text.strip()"],"metadata":{"id":"cNilfKlzApne"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prompting The Model"],"metadata":{"id":"elfAnZnEOsLg"}},{"cell_type":"code","metadata":{"id":"rFq0MpSLtXm"},"source":["import json\n","from pydantic import ValidationError\n","\n","def analyze_content_gaps(input_file: str, output_file: str ):\n","    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n","        content = f.read()\n","\n","    messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"\"\"\n","You are an AI assistant specialized in **Content Gap Analysis**.\n","\n","Your task is to compare **product descriptions** and **customer reviews**, and then identify **common features**, **unique features**, **customer gaps**, and **marketing insights**.\n","\n","You will analyze and reason in English, but your **final output JSON must be entirely in Persian (Farsi)** — including all field names and text values.\n","\n","### Output Format (follow this schema exactly, but translated into Persian)\n","\n","{\n","\"common_features\": [\"...\"],\n","\"unique_features\": {\n","  \"Product_Name_1\": [\"...\"],\n","  \"Product_Name_2\": [\"...\"]\n","},\n","\"customer_gaps\": [\n","  {\n","    \"product_name\": \"...\",\n","    \"review_mentions\": [\"...\"],\n","    \"missing_in_description\": [\"...\"]\n","  }\n","],\n","\"marketing_insight\": \"...\"\n","}\n","\n","### Strict Rules\n","\n","1. **Common Features**\n","   - Identify **core characteristics** that appear in *every* product description.\n","   - These are the most **fundamental and shared qualities** across all products.\n","   - If even one product does **not** mention a feature, **exclude** it — only keep features that are *universally consistent*.\n","   - Think of this section as what defines the “common identity” of the product line.\n","\n","2. **Unique Features**\n","   - Identify **exclusive attributes** that belong *only* to a specific product and are **not mentioned in any others**.\n","   - These are the points that **differentiate** one product from another and make it stand out.\n","   - Exclude anything shared between two or more products — this section must highlight **true uniqueness**.\n","   - **Crucially, every product name listed in 'customer_gaps' must also appear as a key in this 'unique_features' dictionary.**\n","\n","3. **Customer Gaps**\n","   - For each product, analyze customer reviews to find **topics, features, or expectations** customers talk about.\n","   - List those topics in `\"review_mentions\"`.\n","   - In `\"missing_in_description\"`, include **only** the items that appear in reviews but are **absent from that product’s description**.\n","   - These represent **unmet informational needs** — what customers wanted to know or expected to see but didn’t find in the official product description.\n","\n","4. **Missing In Description**\n","   - In this section, explain only the topics or details that were found in customer reviews but missing from the product description.\n","\n","5. **Marketing Insight**\n","   - Write **3–4 concise sentences (in Persian)** summarizing the main findings.\n","   - Highlight what aspects of the product could be **better communicated**, **emphasized**, or **clarified** in marketing materials.\n","   - Suggest how emphasizing certain **features**, **keywords**, or **benefits** could make the product descriptions more **useful**, **appealing**, and **customer-focused**.\n","\n","### Output Requirements\n","\n","- The response must be a **valid JSON object** (parsable with `json.loads()`).\n","- Do **not** include any explanations, comments, or text outside the JSON.\n","- Always use **double quotes** for all keys and string values.\n","- Make sure arrays `[]` and objects `{}` are properly closed.\n","- The number of products is not always constant.\n","- If a product has no reviews, set its customer_gaps list to empty.\n","- Double-check that no feature is missing, even if it's not strongly emphasized in the text.\n","- The input file language may be Persian or English.\n","- Remember: even though you think in English, the final JSON output file and its contents must be written in **Persian (Farsi)**.\n","\"\"\"\n","    },\n","\n","          #Example for better performance\n","\n","         {\n","  \"role\": \"user\",\n","  \"content\": \"\"\"\n","Products:\n","\n","Western Digital My Passport External Hard Drive, 1TB Capacity (digikala):\n","\n","Description:\n","The My Passport external hard drive by Western Digital connects to your computer via a USB 3.0 interface and helps you store data at high speed. The capacity of this drive is 1 terabyte, making it a great option for users with large storage needs. The My Passport external hard drive is compatible with all common operating systems, including various versions of Windows. It comes in multiple colors, offering suitable choices for every taste. The fourth generation of My Passport drives entered the market in 2019 with a beautiful design. Data transfer speed reaches up to 5 gigabits per second. Notably, the lightweight design makes it easy to carry, and its rotation speed is 5400 RPM.\n","\n","Reviews:\n","- \"Friends, can this hard drive connect to a mobile phone? Android?\"\n","- \"Hi, does it support Xbox Series S?\"\n","- \"Hello, which company provides the warranty, and is it valid?\"\n","\n","Western Digital My Passport External Hard Drive, 1TB Capacity (technolife):\n","\n","Description:\n","Weight: 122.4 grams\n","Dimensions: 107.2 × 75 × 11.2 mm\n","Interface: USB 3.0\n","Capacity: 1 TB\n","Head Size: 2.5 inches\n","Data Transfer Speed: 5 Gbps\n","LED Indicator: No\n","Other Features: Automatic backup via software, password protection for security, AES 256-bit encryption support\n","\n","Reviews:\n","- \"Excuse me, can it be used with Windows 11?\"\n","- \"Hi, I wanted to know if it can connect to a MacBook?\"\n","- \"Good morning, I’m a videographer — do you think a 1TB external hard drive is enough for Instagram videos?\"\n","\n","Western Digital My Passport External Hard Drive, 1TB Capacity (arbabashop):\n","\n","Description:\n","Review of WD My Passport 1TB External Hard Drive\n","The Western Digital My Passport 1TB is one of the most popular and best-selling portable hard drives on the market. With its compact and lightweight design, it’s an ideal choice for those looking for a secure space to store personal, work, or backup data. WD has long been recognized as one of the most reputable storage device manufacturers, and the My Passport series is among its flagship products.\n","\n","Design and Build:\n","Compact and lightweight body, perfect for daily carrying\n","Available in various colors for different preferences\n","Uses Micro-B port (compatible with USB 3.2 Gen 1 and USB 2.0)\n","Good build quality with anti-slip design to prevent sliding on surfaces\n","\n","Technical Specifications:\n","Storage Capacity: 1 TB\n","Connection Interface: USB 3.2 Gen 1 (up to 5 Gbps)\n","Security: Hardware AES 256-bit encryption + password protection\n","Software: WD Backup, WD Discovery, WD Security for management and backup\n","Dimensions: 107 × 75 × 11 mm\n","Weight: ~120 g\n","Warranty: 3 years\n","\n","Performance and Speed:\n","According to tests, data transfer speed:\n","Read: around 120–135 MB/s\n","Write: around 110–125 MB/s\n","This speed is excellent for a hard drive of this type and allows easy storage of videos, photos, music, and large files.\n","\n","Advantages:\n","- Affordable and economical price for its capacity\n","- Lightweight and portable design\n","- Hardware encryption support for data security\n","- WD management and backup software\n","- Compatible with both Windows and macOS\n","\"\"\"\n","},\n","         #using own data\n","         {\"role\": \"user\",\"content\": content}\n","    ]\n","\n","\n","    try:\n","        with get_openai_callback() as cb:\n","            response = llm.invoke(messages)\n","\n","        print(cb)  # token usage stats\n","\n","        cleaned = force_json_closure(response.content.strip())\n","        data = json.loads(cleaned)\n","        result = ContentGapAnalysisResult(**data)\n","\n","        with open(output_file, 'w', encoding=\"utf-8\") as f:\n","            json.dump(result.model_dump(by_alias=True), f, indent=2, ensure_ascii=False)\n","\n","        print(\"---------\")\n","        print(f\"✅ Result successfully saved to {output_file}\")\n","\n","    except ValidationError as e:\n","        print(\"\\n Model output does not match expected structure!\")\n","        print(\"-\" * 40)\n","        print(\" Error details:\")\n","        print(e.errors())\n","        print(\"-\" * 40)\n","        print(\" Raw model output:\\n\", response.content)\n","\n","    except Exception as e:\n","        print(\"\\n An unexpected error occurred!\")\n","        print(\"-\" * 40)\n","        print(\" Error details:\", repr(e))\n","        print(\"-\" * 40)\n","        print(\" Raw model output:\\n\", response.content)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = analyze_content_gaps(\"input.txt\",\"output.txt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AuCwLqlOve-","executionInfo":{"status":"ok","timestamp":1760510340318,"user_tz":-210,"elapsed":9508,"user":{"displayName":"محمد حسین","userId":"13927992254442647854"}},"outputId":"e4f7adaf-af36-43ed-c2a1-1fa7cdc6d6fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens Used: 2911\n","\tPrompt Tokens: 2249\n","\t\tPrompt Tokens Cached: 0\n","\tCompletion Tokens: 662\n","\t\tReasoning Tokens: 0\n","Successful Requests: 1\n","Total Cost (USD): $0.00073455\n","---------\n","✅ Result successfully saved to output.txt\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"q9jHp6wBrseg"},"execution_count":null,"outputs":[]}]}